{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-11T19:22:14.499117Z",
     "start_time": "2025-11-11T19:22:14.443130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Flight Delay Data Analysis (2018-2022)\n",
      "================================================================================\n",
      "\n",
      "Loading data files...\n",
      "Reading Parquet files from 2018 to 2022...\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/Users/jorahmormont/PycharmProjects/BigDataFinalProject/Data Analysis/datasets/robikscube/flight-delay-dataset-20182022/versions/4/raw/Combined_Flights_2021.parquet. SQLSTATE: 42K03",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 57\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# Read all Parquet files\u001B[39;00m\n\u001B[1;32m     50\u001B[0m files \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     51\u001B[0m     BASE_PATH \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCombined_Flights_2018.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     52\u001B[0m     BASE_PATH \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCombined_Flights_2019.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     55\u001B[0m     BASE_PATH \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCombined_Flights_2022.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     56\u001B[0m ]\n\u001B[0;32m---> 57\u001B[0m flight_df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparquet\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 使用*展开列表\u001B[39;00m\n\u001B[1;32m     59\u001B[0m total_count \u001B[38;5;241m=\u001B[39m flight_df\u001B[38;5;241m.\u001B[39mcount()\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m✓ Data loaded successfully\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataFinalProject/venv/lib/python3.9/site-packages/pyspark/sql/readwriter.py:642\u001B[0m, in \u001B[0;36mDataFrameReader.parquet\u001B[0;34m(self, *paths, **options)\u001B[0m\n\u001B[1;32m    631\u001B[0m int96RebaseMode \u001B[38;5;241m=\u001B[39m options\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mint96RebaseMode\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_opts(\n\u001B[1;32m    633\u001B[0m     mergeSchema\u001B[38;5;241m=\u001B[39mmergeSchema,\n\u001B[1;32m    634\u001B[0m     pathGlobFilter\u001B[38;5;241m=\u001B[39mpathGlobFilter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    639\u001B[0m     int96RebaseMode\u001B[38;5;241m=\u001B[39mint96RebaseMode,\n\u001B[1;32m    640\u001B[0m )\n\u001B[0;32m--> 642\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jreader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparquet\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_to_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_spark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpaths\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataFinalProject/venv/lib/python3.9/site-packages/py4j/java_gateway.py:1362\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1356\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1357\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1358\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1359\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1361\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1362\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1363\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1365\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1366\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataFinalProject/venv/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py:288\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    284\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 288\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    290\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [PATH_NOT_FOUND] Path does not exist: file:/Users/jorahmormont/PycharmProjects/BigDataFinalProject/Data Analysis/datasets/robikscube/flight-delay-dataset-20182022/versions/4/raw/Combined_Flights_2021.parquet. SQLSTATE: 42K03"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Flight Delay Feature Engineering - Clean Approach\n",
    "不需要join，直接从FlightDate提取特征\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, month, dayofmonth, dayofweek, quarter, weekofyear,\n",
    "    when, lit, date_format, hour, minute\n",
    ")\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Feature Engineering\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load data\n",
    "BASE_PATH = \"/Users/jorahmormont/PycharmProjects/BigDataFinalProject/datasets/robikscube/flight-delay-dataset-20182022/versions/4/\"\n",
    "\n",
    "flight_df = spark.read.parquet(\n",
    "    BASE_PATH + \"Combined_Flights_2018.parquet\",\n",
    "    BASE_PATH + \"Combined_Flights_2019.parquet\",\n",
    "    BASE_PATH + \"Combined_Flights_2020.parquet\",\n",
    "    BASE_PATH + \"Combined_Flights_2021.parquet\",\n",
    "    BASE_PATH + \"Combined_Flights_2022.parquet\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Feature Engineering - Clean Approach (No Join Required)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Basic Temporal Features (从FlightDate直接提取)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n1. Extracting basic temporal features...\")\n",
    "\n",
    "flight_df = flight_df \\\n",
    "    .withColumn('month', month('FlightDate')) \\\n",
    "    .withColumn('day_of_month', dayofmonth('FlightDate')) \\\n",
    "    .withColumn('day_of_week', dayofweek('FlightDate')) \\\n",
    "    .withColumn('quarter', quarter('FlightDate')) \\\n",
    "    .withColumn('week_of_year', weekofyear('FlightDate'))\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Weekend Indicator (周末标识)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"2. Creating weekend indicator...\")\n",
    "\n",
    "flight_df = flight_df.withColumn(\n",
    "    'is_weekend',\n",
    "    when(col('day_of_week').isin([1, 7]), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Major Holidays (主要节假日 - 不需要外部数据)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"3. Creating major holiday indicators...\")\n",
    "\n",
    "# New Year's Day (1/1)\n",
    "flight_df = flight_df.withColumn(\n",
    "    'is_new_year',\n",
    "    when((month('FlightDate') == 1) & (dayofmonth('FlightDate') == 1), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Independence Day (7/4)\n",
    "flight_df = flight_df.withColumn(\n",
    "    'is_july_4th',\n",
    "    when((month('FlightDate') == 7) & (dayofmonth('FlightDate') == 4), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Christmas (12/25)\n",
    "flight_df = flight_df.withColumn(\n",
    "    'is_christmas',\n",
    "    when((month('FlightDate') == 12) & (dayofmonth('FlightDate') == 25), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Thanksgiving (11月第四个周四 - 22-28号之间的周四)\n",
    "flight_df = flight_df.withColumn(\n",
    "    'is_thanksgiving',\n",
    "    when(\n",
    "        (month('FlightDate') == 11) &\n",
    "        (dayofweek('FlightDate') == 5) &  # Thursday\n",
    "        (dayofmonth('FlightDate').between(22, 28)),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Memorial Day (5月最后一个周一)\n",
    "flight_df = flight_df.withColumn(\n",
    "    'is_memorial_day',\n",
    "    when(\n",
    "        (month('FlightDate') == 5) &\n",
    "        (dayofweek('FlightDate') == 2) &  # Monday\n",
    "        (dayofmonth('FlightDate') >= 25),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Labor Day (9月第一个周一)\n",
    "flight_df = flight_df.withColumn(\n",
    "    'is_labor_day',\n",
    "    when(\n",
    "        (month('FlightDate') == 9) &\n",
    "        (dayofweek('FlightDate') == 2) &  # Monday\n",
    "        (dayofmonth('FlightDate') <= 7),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Any major holiday\n",
    "flight_df = flight_df.withColumn(\n",
    "    'is_major_holiday',\n",
    "    when(\n",
    "        (col('is_new_year') == 1) |\n",
    "        (col('is_july_4th') == 1) |\n",
    "        (col('is_christmas') == 1) |\n",
    "        (col('is_thanksgiving') == 1) |\n",
    "        (col('is_memorial_day') == 1) |\n",
    "        (col('is_labor_day') == 1),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Holiday Proximity (节假日前后)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"4. Creating holiday proximity features...\")\n",
    "\n",
    "# Day before/after major holidays\n",
    "flight_df = flight_df.withColumn(\n",
    "    'near_new_year',\n",
    "    when(\n",
    "        (month('FlightDate') == 1) & (dayofmonth('FlightDate').between(1, 2)) |\n",
    "        (month('FlightDate') == 12) & (dayofmonth('FlightDate').between(30, 31)),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "flight_df = flight_df.withColumn(\n",
    "    'near_christmas',\n",
    "    when(\n",
    "        (month('FlightDate') == 12) & (dayofmonth('FlightDate').between(23, 26)),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "flight_df = flight_df.withColumn(\n",
    "    'near_thanksgiving',\n",
    "    when(\n",
    "        (month('FlightDate') == 11) & (dayofmonth('FlightDate').between(22, 29)),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. Seasonal Features (季节特征)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"5. Creating seasonal features...\")\n",
    "\n",
    "# Holiday season (感恩节到新年)\n",
    "flight_df = flight_df.withColumn(\n",
    "    'is_holiday_season',\n",
    "    when(\n",
    "        ((month('FlightDate') == 11) & (dayofmonth('FlightDate') >= 22)) |\n",
    "        (month('FlightDate') == 12) |\n",
    "        ((month('FlightDate') == 1) & (dayofmonth('FlightDate') <= 2)),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Summer travel season (6-8月)\n",
    "flight_df = flight_df.withColumn(\n",
    "    'is_summer_travel',\n",
    "    when(month('FlightDate').between(6, 8), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Spring break (3月中旬到4月初)\n",
    "flight_df = flight_df.withColumn(\n",
    "    'is_spring_break_period',\n",
    "    when(\n",
    "        ((month('FlightDate') == 3) & (dayofmonth('FlightDate') >= 15)) |\n",
    "        ((month('FlightDate') == 4) & (dayofmonth('FlightDate') <= 10)),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. Time of Day Features (如果有CRSDepTime)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"6. Creating time of day features...\")\n",
    "\n",
    "if 'CRSDepTime' in flight_df.columns:\n",
    "    # CRSDepTime格式是HHMM (如: 1430 = 14:30)\n",
    "    flight_df = flight_df.withColumn(\n",
    "        'dep_hour',\n",
    "        (col('CRSDepTime') / 100).cast('int')\n",
    "    )\n",
    "\n",
    "    # Time of day categories\n",
    "    flight_df = flight_df.withColumn(\n",
    "        'time_of_day',\n",
    "        when(col('dep_hour').between(6, 11), 'morning')\n",
    "        .when(col('dep_hour').between(12, 17), 'afternoon')\n",
    "        .when(col('dep_hour').between(18, 21), 'evening')\n",
    "        .otherwise('night')\n",
    "    )\n",
    "\n",
    "    # Peak hours\n",
    "    flight_df = flight_df.withColumn(\n",
    "        'is_peak_hour',\n",
    "        when(col('dep_hour').between(7, 9) | col('dep_hour').between(17, 19), 1)\n",
    "        .otherwise(0)\n",
    "    )\n",
    "\n",
    "# ============================================================================\n",
    "# 7. Show Results\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Feature Engineering Complete!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select new feature columns\n",
    "feature_cols = [\n",
    "    'FlightDate', 'Year', 'Month',\n",
    "    'month', 'day_of_month', 'day_of_week', 'quarter', 'week_of_year',\n",
    "    'is_weekend', 'is_major_holiday',\n",
    "    'is_new_year', 'is_july_4th', 'is_christmas', 'is_thanksgiving',\n",
    "    'near_new_year', 'near_christmas', 'near_thanksgiving',\n",
    "    'is_holiday_season', 'is_summer_travel', 'is_spring_break_period'\n",
    "]\n",
    "\n",
    "if 'dep_hour' in flight_df.columns:\n",
    "    feature_cols.extend(['dep_hour', 'time_of_day', 'is_peak_hour'])\n",
    "\n",
    "print(\"\\nNew features created:\")\n",
    "for col_name in feature_cols[8:]:  # Skip original columns\n",
    "    print(f\"  ✓ {col_name}\")\n",
    "\n",
    "print(\"\\nSample data with new features:\")\n",
    "flight_df.select(feature_cols).show(10)\n",
    "\n",
    "# ============================================================================\n",
    "# 8. Feature Statistics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Feature Statistics\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Weekend flights\n",
    "weekend_stats = flight_df.groupBy('is_weekend').count()\n",
    "print(\"\\nWeekend vs Weekday:\")\n",
    "weekend_stats.show()\n",
    "\n",
    "# Major holiday flights\n",
    "holiday_stats = flight_df.groupBy('is_major_holiday').count()\n",
    "print(\"\\nMajor Holiday vs Regular Day:\")\n",
    "holiday_stats.show()\n",
    "\n",
    "# Holiday season\n",
    "holiday_season_stats = flight_df.groupBy('is_holiday_season').count()\n",
    "print(\"\\nHoliday Season vs Regular Season:\")\n",
    "holiday_season_stats.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 9. Delay Analysis by Features\n",
    "# ============================================================================\n",
    "\n",
    "if 'DepDel15' in flight_df.columns:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Delay Rates by Features\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Weekend\n",
    "    print(\"\\nDelay Rate - Weekend vs Weekday:\")\n",
    "    flight_df.filter(col('Cancelled') == 0).groupBy('is_weekend') \\\n",
    "        .agg((sum('DepDel15') / count('*') * 100).alias('delay_rate_pct')) \\\n",
    "        .show()\n",
    "\n",
    "    # Major holidays\n",
    "    print(\"\\nDelay Rate - Major Holiday vs Regular:\")\n",
    "    flight_df.filter(col('Cancelled') == 0).groupBy('is_major_holiday') \\\n",
    "        .agg((sum('DepDel15') / count('*') * 100).alias('delay_rate_pct')) \\\n",
    "        .show()\n",
    "\n",
    "    # Holiday season\n",
    "    print(\"\\nDelay Rate - Holiday Season vs Regular:\")\n",
    "    flight_df.filter(col('Cancelled') == 0).groupBy('is_holiday_season') \\\n",
    "        .agg((sum('DepDel15') / count('*') * 100).alias('delay_rate_pct')) \\\n",
    "        .show()\n",
    "\n",
    "    # Summer travel\n",
    "    print(\"\\nDelay Rate - Summer vs Other Seasons:\")\n",
    "    flight_df.filter(col('Cancelled') == 0).groupBy('is_summer_travel') \\\n",
    "        .agg((sum('DepDel15') / count('*') * 100).alias('delay_rate_pct')) \\\n",
    "        .show()\n",
    "\n",
    "# ============================================================================\n",
    "# 10. Save Enhanced Dataset\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Saving Enhanced Dataset\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "output_path = \"flight_data_with_features.parquet\"\n",
    "flight_df.write.mode('overwrite').parquet(output_path)\n",
    "\n",
    "print(f\"\\n✓ Enhanced dataset saved to: {output_path}\")\n",
    "print(f\"  Total records: {flight_df.count():,}\")\n",
    "print(f\"  Total columns: {len(flight_df.columns)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ Feature Engineering Complete!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "Summary:\n",
    "✓ No external data join required\n",
    "✓ All features derived from FlightDate\n",
    "✓ Clean and efficient approach\n",
    "✓ Ready for model training\n",
    "\n",
    "Next steps:\n",
    "1. Add weather features (if needed)\n",
    "2. Feature selection\n",
    "3. Model training\n",
    "\"\"\")\n",
    "\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "55f4bc4ed06993a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
